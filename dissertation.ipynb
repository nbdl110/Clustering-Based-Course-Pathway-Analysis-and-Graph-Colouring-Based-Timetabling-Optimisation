{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127846a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "df = pd.read_excel(\"C:/Users/myWan/Desktop/HDS Optional Enrolments Anonymised.xlsx\", sheet_name=\"Export\")\n",
    "\n",
    "# retain colomns needed\n",
    "df = df[['Student ID Pseudonymised', 'Long Course Title']]\n",
    "\n",
    "# one-hot encoding\n",
    "student_course_matrix = pd.crosstab(df['Student ID Pseudonymised'], df['Long Course Title'])\n",
    "\n",
    "# check the data\n",
    "print(student_course_matrix.shape)\n",
    "student_course_matrix.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# course category casting\n",
    "course_category = {\n",
    "    'Machine Learning and Advanced Data Methods': 'AI',\n",
    "    'Digital Transformation Project': 'Informatics',\n",
    "    'Introduction to Health Informatics': 'Informatics',\n",
    "    'Introduction to Clinical Bioinformatics':'Informatics',\n",
    "    'Tutorials in Advanced Statistics': 'Statistics',\n",
    "    'Decision Support Systems':'Informatics',\n",
    "    'Mathematical Computing for Medical Imaging':'AI',\n",
    "    'Multi-omics for Healthcare':'Informatics',\n",
    "    'Design and Analysis of Randomised Controlled Trials':'Statistics',\n",
    "    'Principles of Digital Biology':'Informatics',\n",
    "    'Applied Epidemiology':'Informatics'\n",
    "}\n",
    "# category feature\n",
    "for cat in set(course_category.values()):\n",
    "    student_course_matrix[cat] = 0\n",
    "\n",
    "for course in student_course_matrix.columns:\n",
    "    category = course_category.get(course)\n",
    "    if category:\n",
    "        student_course_matrix[category] += student_course_matrix[course]\n",
    "\n",
    "\n",
    "# normalisation\n",
    "features_to_scale = ['AI', 'Informatics', 'Statistics']\n",
    "scaler = StandardScaler()\n",
    "student_course_matrix[features_to_scale] = scaler.fit_transform(student_course_matrix[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA process\n",
    "X_courses = student_course_matrix.drop(features_to_scale, axis=1)\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X_courses)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "components = np.arange(1, len(explained_variance_ratio) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=300) \n",
    "# variance for each PC\n",
    "plt.plot(components, explained_variance_ratio, 'o-', label='Individual Explained Variance', color='blue')\n",
    "for i, v in enumerate(explained_variance_ratio):\n",
    "    plt.text(i + 1, v + 0.01, f\"{v*100:.1f}%\", ha='center', fontsize=8, color='blue')\n",
    "\n",
    "# accumulated variance\n",
    "plt.plot(components, cumulative_variance, 's--', label='Cumulative Explained Variance', color='green')\n",
    "for i, v in enumerate(cumulative_variance):\n",
    "    plt.text(i + 1, v - 0.05, f\"{v*100:.1f}%\", ha='center', fontsize=8, color='green')\n",
    "\n",
    "plt.title('Scree Plot of PCA Components', fontsize=12)\n",
    "plt.xlabel('Principal Component', fontsize=10)\n",
    "plt.ylabel('Explained Variance Ratio', fontsize=10)\n",
    "plt.xticks(components)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"scree_plot.png\", dpi=300)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd423f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_pca)\n",
    "student_course_matrix['DBSCAN'] = dbscan_labels\n",
    "\n",
    "# evaluation function\n",
    "def evaluate_clustering(name, labels, X):\n",
    "    if name == 'DBSCAN' and (len(set(labels)) <= 1 or (len(set(labels)) == 2 and -1 in labels)):\n",
    "        print(f\"{name} Result is invalid\")\n",
    "        return\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(\"Silhouette Score:\", silhouette_score(X, labels))\n",
    "    print(\"Calinski-Harabasz:\", calinski_harabasz_score(X, labels))\n",
    "    print(\"Davies-Bouldin:\", davies_bouldin_score(X, labels))\n",
    "\n",
    "# DBSCAN evaluation\n",
    "evaluate_clustering(\"DBSCAN\", dbscan_labels, X_pca)\n",
    "\n",
    "# different k\n",
    "cluster_results = {}\n",
    "k_values = [2, 3, 4]\n",
    "\n",
    "for k in k_values:\n",
    "    # KMeans\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_labels = kmeans.fit_predict(X_pca)\n",
    "    col_kmeans = f'KMeans_k={k}'\n",
    "    student_course_matrix[col_kmeans] = kmeans_labels\n",
    "    cluster_results[col_kmeans] = kmeans_labels\n",
    "    evaluate_clustering(f'KMeans (k={k})', kmeans_labels, X_pca)\n",
    "\n",
    "    # Spectral Clustering\n",
    "    spectral = SpectralClustering(n_clusters=k, affinity='nearest_neighbors', n_neighbors=10, random_state=42)\n",
    "    spectral_labels = spectral.fit_predict(X_courses)\n",
    "    col_spectral = f'Spectral_k={k}'\n",
    "    student_course_matrix[col_spectral] = spectral_labels\n",
    "    cluster_results[col_spectral] = spectral_labels\n",
    "    evaluate_clustering(f'Spectral Clustering (k={k})', spectral_labels, X_courses)\n",
    "\n",
    "# cluster interpretation\n",
    "for name, labels in cluster_results.items():\n",
    "    print(f\"\\n{name} Cluster Summary:\")\n",
    "    for cluster_id in sorted(set(labels)):\n",
    "        group = student_course_matrix[student_course_matrix[name] == cluster_id]\n",
    "        print(f\"Cluster {cluster_id} - {len(group)} students:\")\n",
    "        print(group[features_to_scale].mean())\n",
    "\n",
    "# visualisation\n",
    "\n",
    "def plot_clusters_discrete(X2d, labels, title):\n",
    "    labels = np.asarray(labels)\n",
    "    uniq = sorted(np.unique(labels))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for i, cid in enumerate(uniq):\n",
    "        mask = (labels == cid)\n",
    "        if cid == -1:\n",
    "            # DBSCAN noise\n",
    "            plt.scatter(X2d[mask, 0], X2d[mask, 1],\n",
    "                        s=45, marker='x', alpha=0.8, label='Noise (-1)')\n",
    "        else:\n",
    "            plt.scatter(X2d[mask, 0], X2d[mask, 1],\n",
    "                        s=45, alpha=0.8, label=f'Cluster {cid}')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "    plt.legend(loc='best', frameon=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "X_pca_2d = X_pca[:, :2]\n",
    "\n",
    "for name, labels in cluster_results.items():\n",
    "    plot_clusters_discrete(X_pca_2d, labels, f\"PCA Visualization (PC1 vs PC2) - {name}\")\n",
    "\n",
    "plot_clusters_discrete(X_pca_2d, dbscan_labels, \"PCA Visualization (PC1 vs PC2) - DBSCAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timetable Opitimisation\n",
    "# delete Applied Epidemiology \n",
    "df = df[df['Long Course Title'] != 'Applied Epidemiology']\n",
    "df = df[df['Long Course Title'] != 'Multi-omics for Healthcare']\n",
    "# course cooccurrence matrix\n",
    "students = df['Student ID Pseudonymised'].unique()\n",
    "courses = df['Long Course Title'].unique()\n",
    "co_matrix = pd.DataFrame(0, index=courses, columns=courses)\n",
    "\n",
    "for student in students:\n",
    "    selected_courses = df[df['Student ID Pseudonymised'] == student]['Long Course Title'].unique()\n",
    "    for i in range(len(selected_courses)):\n",
    "        for j in range(i + 1, len(selected_courses)):\n",
    "            co_matrix.loc[selected_courses[i], selected_courses[j]] += 1\n",
    "            co_matrix.loc[selected_courses[j], selected_courses[i]] += 1\n",
    "\n",
    "co_matrix_normalized = co_matrix / len(students)\n",
    "thresholds = [0.01, 0.05, 0.1]\n",
    "for threshold in thresholds:\n",
    "# course conflict graph\n",
    "    G = nx.Graph()\n",
    "    for course in courses:\n",
    "        G.add_node(course)\n",
    "\n",
    "    for i in courses:\n",
    "        for j in courses:\n",
    "            if i != j and co_matrix_normalized.loc[i, j] > threshold:\n",
    "                G.add_edge(i, j, weight=co_matrix_normalized.loc[i, j])\n",
    "\n",
    "# graph colouring\n",
    "    coloring = nx.coloring.greedy_color(G, strategy='largest_first')\n",
    "    print(\"\\nRecommended Timetable Allocation (Greedy Coloring):\")\n",
    "    for course, slot in coloring.items():\n",
    "        print(f\"{course}: Time Slot {slot}\")\n",
    "\n",
    "# low-conflict course pairs\n",
    "co_matrix_long = co_matrix_normalized.stack().reset_index()\n",
    "co_matrix_long.columns = ['Course1', 'Course2', 'Co_Occurrence']\n",
    "co_matrix_long = co_matrix_long[co_matrix_long['Course1'] != co_matrix_long['Course2']]\n",
    "co_matrix_long['Pair'] = co_matrix_long.apply(lambda row: tuple(sorted([row['Course1'], row['Course2']])), axis=1)\n",
    "co_matrix_long = co_matrix_long.drop_duplicates(subset=['Pair'])\n",
    "\n",
    "# 10 lowest\n",
    "lowest_pairs = co_matrix_long.sort_values(by='Co_Occurrence').head(10)\n",
    "print(\"\\nSuggested course pairs that can be allowed to clash (lowest conflict pairs):\")\n",
    "for idx, row in lowest_pairs.iterrows():\n",
    "    print(f\"{row['Course1']} & {row['Course2']}: Co-occurrence rate = {row['Co_Occurrence']*100:.2f}%\")\n",
    "\n",
    "# conflict heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(co_matrix_normalized, cmap='Reds', xticklabels=True, yticklabels=True)\n",
    "plt.title(\"Course Co-occurrence Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
